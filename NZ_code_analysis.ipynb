{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.options.display.width = None\n",
    "from glob import glob as g\n",
    "import matplotlib as plot\n",
    "import logging\n",
    "import time\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "import random\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Change the default settings of matplotlib\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams['figure.dpi'] = 300  # Set the DPI to 100 globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv_file\n",
    "finasteride = pd.read_csv('link')\n",
    "tamsulosin = pd.read_csv('link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take out the year value in the date_dispensed column and count the unique number of years\n",
    "finasteride['year'] = finasteride['DATE_DISPENSED'].str[:4]\n",
    "finasteride['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take out the year value in the date_dispensed column and count the unique number of years\n",
    "tamsulosin['year'] = tamsulosin['DATE_DISPENSED'].str[:4]\n",
    "tamsulosin['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reassign the treament group\n",
    "print(f'There are {len(tamsulosin)} patients in the tamsulosin group')\n",
    "tamsulosin['Treatment'] = 1\n",
    "\n",
    "print(f'There are {len(finasteride)} patients in the finasteride group')\n",
    "finasteride['Treatment'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median of duration_year for finasteride\n",
    "print(f\"The median duration following-up of finasteride is :{finasteride['duration_year'].median()}\") \n",
    "#median of duration_year for tamsulosin\n",
    "print(f\"The median duration following-up of finasteride is :{tamsulosin['duration_year'].median()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.get_cachedir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'is_dead' based on 'DOD'\n",
    "finasteride['is_dead'] = np.where(finasteride['DOD'].notnull() & finasteride['DATE_DISPENSED_insulin'].isnull(), 1, 0)\n",
    "tamsulosin['is_dead'] = np.where(tamsulosin['DOD'].notnull() & tamsulosin['DATE_DISPENSED_insulin'].isnull(), 1, 0)\n",
    "\n",
    "# Calculate the proportion of dead patients for each treatment\n",
    "prop_dead_finasteride = finasteride['is_dead'].mean()\n",
    "prop_dead_tamsulosin = tamsulosin['is_dead'].mean()\n",
    "\n",
    "# Data to plot\n",
    "proportions = [prop_dead_finasteride, prop_dead_tamsulosin]\n",
    "treatment_labels = ['Finasteride', 'Tamsulosin']\n",
    "\n",
    "# Create bar plot\n",
    "plt.bar(treatment_labels, proportions, color=['red', 'blue'])\n",
    "plt.xlabel('Treatment')\n",
    "plt.ylabel('Proportion of Dead Patients')\n",
    "plt.title('Proportion of Dead Patients by Treatment')\n",
    "plt.show()\n",
    "\n",
    "print(f'Death account for {round(prop_dead_finasteride,2)} of finasteride group.')\n",
    "print(f'Death account for {round(prop_dead_tamsulosin,2)} of tamsulosin group.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix up data sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapping ethnicity variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to map original ethnicity codes to the new grouped categories\n",
    "def group_and_map_ethnicity(df, ethnicity):\n",
    "    # Create a function to map original ethnicity codes to the new grouped categories\n",
    "    def map_ethnicity(ethnicity_code):\n",
    "        if ethnicity_code in [11, 12, 10]:\n",
    "            return 'European'\n",
    "        elif ethnicity_code in [40, 41, 42, 43, 44, 51]:\n",
    "            return 'Asian'\n",
    "        elif ethnicity_code in [21, 31, 33, 35, 36, 34, 37]:\n",
    "            return 'Indigenous'\n",
    "        else:\n",
    "            return 'Not_Stated/Other/Unknown'\n",
    "\n",
    "    # Apply the map_ethnicity function to create a new ethnicity_grouped column\n",
    "    df['ethnicity_grouped'] = df[ethnicity].apply(map_ethnicity)\n",
    "\n",
    "    # Create dummy variables for the ethnicity_grouped categories\n",
    "    ethnicity_grouped_dummies = pd.get_dummies(df['ethnicity_grouped'], prefix='ethnicity')\n",
    "\n",
    "    # Convert the ethnicity_grouped variable to categorical format in pandas DataFrame\n",
    "    df['ethnicity_grouped'] = df['ethnicity_grouped'].astype('category')\n",
    "\n",
    "    # Concatenate the dummy variables with the original DataFrame\n",
    "    df = pd.concat([df, ethnicity_grouped_dummies], axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finasteride_df = finasteride.copy()\n",
    "tamsulosin_df = tamsulosin.copy()\n",
    "\n",
    "# Apply ethnicity function\n",
    "finasteride_df= group_and_map_ethnicity(finasteride_df, 'ethnicity') \n",
    "tamsulosin_df= group_and_map_ethnicity(tamsulosin_df, 'ethnicity') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_tam_df = pd.concat([tamsulosin_df, finasteride_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ranksums, chi2_contingency\n",
    "\n",
    "def summarize_variables(df, variables, grouped_variables):\n",
    "    summary_rows = []\n",
    "    # Create the summary row\n",
    "    summary_row = {\n",
    "    'Variable': 'Number of Patients',\n",
    "    'Tamsulosin': len(df[df['Treatment'] == 1]),\n",
    "    'Finasteride': len(df[df['Treatment'] == 0]),\n",
    "    }\n",
    "    # Append the summary row to the list\n",
    "    summary_rows.append(summary_row)\n",
    "    for category, var_list in grouped_variables.items():  \n",
    "        summary_rows.append({'Variable': category, 'Tamsulosin': '', 'Finasteride': '', 'p-value': ''})      \n",
    "        for variable in var_list:\n",
    "            if variable in variables:\n",
    "                row_data = {'Variable': f\"  {variable}\"}\n",
    "                for treatment, treatment_name in [(1, 'Tamsulosin'), (0, 'Finasteride')]:\n",
    "                    group = df[df['Treatment'] == treatment]\n",
    "                    if variable in ['start_age', 'duration_year']:\n",
    "                        mean = group[variable].mean()\n",
    "                        std = group[variable].std()\n",
    "                        value = f\"{mean:.2f} ({std:.2f})\"\n",
    "                    elif variable in ['diabetes_duration','cci_score']:\n",
    "                        median = group[variable].median()\n",
    "                        iqr = group[variable].quantile(0.75) - group[variable].quantile(0.25)\n",
    "                        value = f\"{median:.2f} ({iqr:.2f})\"\n",
    "                    else:\n",
    "                        count = group[variable].sum()\n",
    "                        percentage = (count / len(group)) * 100\n",
    "                        value = f\"{count} ({percentage:.2f}%)\"\n",
    "                        \n",
    "                    row_data[treatment_name] = value\n",
    "                \n",
    "                if category != 'Ethnicity':\n",
    "                    # Conduct appropriate statistical test and get p-value\n",
    "                    if variable in ['start_age', 'duration_year']:\n",
    "                        _, p_value = ttest_ind(df[df['Treatment'] == 0][variable], df[df['Treatment'] == 1][variable])\n",
    "                    elif variable in ['diabetes_duration','cci_score']:\n",
    "                        _, p_value = ranksums(df[df['Treatment'] == 0][variable], df[df['Treatment'] == 1][variable])\n",
    "                    else:\n",
    "                        contingency_table = pd.crosstab(df['Treatment'], df[variable])\n",
    "                        _, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "                    row_data['p-value'] = f\"{p_value:.3f}\"\n",
    "                else:\n",
    "                    row_data['p-value'] = ''\n",
    "\n",
    "                summary_rows.append(row_data)\n",
    "            \n",
    "        if category == 'Ethnicity':\n",
    "            row_data = {'Variable': f\"  {category} (all)\", 'Tamsulosin': '', 'Finasteride': '', 'p-value': ''}\n",
    "            # Conduct chi-square test for the whole ethnicity variable\n",
    "            contingency_table = pd.crosstab(df['Treatment'], [df[var] for var in var_list])\n",
    "            _, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "            row_data['p-value'] = f\"{p_value:.3f}\"\n",
    "            summary_rows.append(row_data)\n",
    "\n",
    "    summary_table = pd.DataFrame(summary_rows)\n",
    "    return summary_table\n",
    "\n",
    "grouped_variables = {\n",
    "    '': ['start_age', #'second_hospitalisation'\n",
    "         'duration_year', 'cci_score', 'diabetes_duration'],\n",
    "         'Diabetes medication': ['metformin','sulfonylureas','acarbose','GLP_1','DPP_4','SGLT_2'],\n",
    "    'Other drug use': ['ACE_inhibitors', 'ARBs', 'Beta_blocker', 'corticosteroid', 'diuretics', 'statin'],\n",
    "    'Ethnicity': ['ethnicity_European','ethnicity_Asian', \n",
    "                  'ethnicity_Indigenous', 'ethnicity_Not_Stated/Other/Unknown']\n",
    "}\n",
    "summary_variables = ['duration_year', #just to check- to be removed\n",
    "   'start_age','diabetes_duration', 'cci_score',#'second_hospitalisation',\n",
    "   'ACE_inhibitors', 'ARBs' ,'Beta_blocker', 'corticosteroid', 'diuretics', 'statin',\n",
    "   'metformin','sulfonylureas','acarbose','GLP_1','DPP_4','SGLT_2',\n",
    "   'ethnicity_European','ethnicity_Asian', 'ethnicity_Indigenous', 'ethnicity_Not_Stated/Other/Unknown',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_variables(fin_tam_df, summary_variables, grouped_variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sumary table for weighted propensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate standardized difference\n",
    "def calculate_standardized_diff(df, variable, for_means):\n",
    "    tamsulosin_group = df[df['Treatment'] == 1][variable]\n",
    "    finasteride_group = df[df['Treatment'] == 0][variable]\n",
    "    \n",
    "    if for_means: #for continuos variable\n",
    "        mean_tamsulosin = tamsulosin_group.mean()\n",
    "        mean_finasteride = finasteride_group.mean()\n",
    "        \n",
    "        pooled_std = np.sqrt((tamsulosin_group.std() ** 2 + finasteride_group.std() ** 2) / 2)\n",
    "        \n",
    "        std_diff = abs((mean_tamsulosin - mean_finasteride) / pooled_std)\n",
    "    else: #for categorial variables\n",
    "        prop_tamsulosin = tamsulosin_group.sum() / len(tamsulosin_group)\n",
    "        prop_finasteride = finasteride_group.sum() / len(finasteride_group)\n",
    "        \n",
    "        std_diff = abs( \n",
    "            (prop_tamsulosin - prop_finasteride) / \n",
    "            np.sqrt( (prop_tamsulosin*(1 - prop_tamsulosin) + \n",
    "                      prop_finasteride*(1- prop_finasteride)) / 2) ) \n",
    "    \n",
    "    return std_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate standardized difference with weights\n",
    "def calculate_weighted_standardized_diff(df, variable, weights, for_means):\n",
    "    tamsulosin_group = df[df['Treatment'] == 1][[variable, weights]]\n",
    "    finasteride_group = df[df['Treatment'] == 0][[variable, weights]]\n",
    "\n",
    "    if for_means: #for continuous variable\n",
    "        weighted_mean_tamsulosin = np.average(tamsulosin_group[variable], weights=tamsulosin_group[weights])\n",
    "        weighted_mean_finasteride = np.average(finasteride_group[variable], weights=finasteride_group[weights])\n",
    "\n",
    "        weighted_var_tamsulosin = np.average((tamsulosin_group[variable]-weighted_mean_tamsulosin)**2, weights=tamsulosin_group[weights])\n",
    "        weighted_var_finasteride = np.average((finasteride_group[variable]-weighted_mean_finasteride)**2, weights=finasteride_group[weights])\n",
    "\n",
    "        pooled_weighted_std = np.sqrt((weighted_var_tamsulosin + weighted_var_finasteride) / 2)\n",
    "\n",
    "        std_diff = abs((weighted_mean_tamsulosin - weighted_mean_finasteride) / pooled_weighted_std)\n",
    "    else: #for categorical variables\n",
    "        weighted_prop_tamsulosin = tamsulosin_group.loc[tamsulosin_group[variable] == 1, weights].sum() / tamsulosin_group[weights].sum()\n",
    "        weighted_prop_finasteride = finasteride_group.loc[finasteride_group[variable] == 1, weights].sum() / finasteride_group[weights].sum()\n",
    "\n",
    "        std_diff = abs(\n",
    "            (weighted_prop_tamsulosin - weighted_prop_finasteride) / \n",
    "            np.sqrt( (weighted_prop_tamsulosin*(1 - weighted_prop_tamsulosin) + \n",
    "                      weighted_prop_finasteride*(1 - weighted_prop_finasteride)) / 2) )\n",
    "\n",
    "    return std_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_variables_before_weighted(df, variables, grouped_variables):\n",
    "    summary_rows = []\n",
    "    #Create the summary row\n",
    "    summary_row = {\n",
    "    'Variable': 'Number of Patients',\n",
    "    'Tamsulosin': len(df[df['Treatment'] == 1]),\n",
    "    'Finasteride': len(df[df['Treatment'] == 0]),\n",
    "    }\n",
    "    # Append the summary row to the list\n",
    "    summary_rows.append(summary_row)\n",
    "    for category, var_list in grouped_variables.items():\n",
    "        if category == 'Ethnicity':\n",
    "            # Create a binary variable for dominant ethnicity (true = dominant ethnicity, false = other)\n",
    "            dominant_ethnicity = df[['ethnicity_European', 'ethnicity_Asian', 'ethnicity_Indigenous', 'ethnicity_Not_Stated/Other/Unknown']].sum().idxmax()\n",
    "            df['dominant_ethnicity'] = df[dominant_ethnicity].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "            # calculate overall standardized difference for 'Ethnicity'\n",
    "            std_diff = calculate_standardized_diff(df, 'dominant_ethnicity', for_means=False)\n",
    "            row_data = {'Variable': \"  White vs others\", 'Tamsulosin': '', 'Finasteride': '', 'Std Difference': f\"{std_diff:.2f}\"}\n",
    "            summary_rows.append(row_data)\n",
    "            \n",
    "            # Drop the temporary dominant ethnicity column\n",
    "            df.drop(columns='dominant_ethnicity', inplace=True)\n",
    "            \n",
    "        for variable in var_list:\n",
    "            if variable in variables:\n",
    "                row_data = {'Variable': f\"    {variable}\"}\n",
    "                for treatment, treatment_name in [(1, 'Tamsulosin'), (0, 'Finasteride')]:\n",
    "                    group = df[df['Treatment'] == treatment]\n",
    "                    if variable in ['start_age', 'duration_year', 'diabetes_duration', 'cci_score']:\n",
    "                        mean = group[variable].mean()\n",
    "                        std = group[variable].std()\n",
    "                        value = f\"{mean:.2f} ({std:.2f})\"\n",
    "                    else:\n",
    "                        count = group[variable].sum()\n",
    "                        percentage = (count / len(group)) * 100\n",
    "                        value = f\"{count} ({percentage:.2f}%)\"\n",
    "                    \n",
    "                    row_data[treatment_name] = value\n",
    "                \n",
    "                # calculate standardized difference for continuous variables\n",
    "                if category != 'Ethnicity':\n",
    "                    if variable in ['start_age', 'duration_year', 'diabetes_duration', 'cci_score']:\n",
    "                        std_diff = calculate_standardized_diff(df, variable, for_means=True)\n",
    "                    else: #for catgeorical variables\n",
    "                        std_diff = calculate_standardized_diff(df, variable, for_means=False)\n",
    "                        \n",
    "                    row_data['Std Difference'] = f\"{std_diff:.3f}\"\n",
    "                \n",
    "                summary_rows.append(row_data)\n",
    "            \n",
    "    summary_table = pd.DataFrame(summary_rows)\n",
    "    return summary_table\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary variables after weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary the weights for each patient\n",
    "def summarize_variables_after_weighted(df, variables, grouped_variables, weights_variable):\n",
    "    summary_rows = []\n",
    "    #Create the summary row\n",
    "    summary_row = {\n",
    "    'Variable': 'Number of Patients',\n",
    "    'Tamsulosin': len(df[df['Treatment'] == 1]),\n",
    "    'Finasteride': len(df[df['Treatment'] == 0]),\n",
    "    }\n",
    "    # Append the summary row to the list\n",
    "    summary_rows.append(summary_row)\n",
    "    for category, var_list in grouped_variables.items():\n",
    "        if category == 'Ethnicity':\n",
    "            # Create a binary variable for dominant ethnicity (true = dominant ethnicity, false = other)\n",
    "            dominant_ethnicity = df[['ethnicity_European', 'ethnicity_Asian', 'ethnicity_Indigenous', 'ethnicity_Not_Stated/Other/Unknown']].sum().idxmax()\n",
    "            df['dominant_ethnicity'] = df[dominant_ethnicity].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "            # calculate overall standardized difference for 'Ethnicity'\n",
    "            std_diff = calculate_standardized_diff(df, 'dominant_ethnicity', for_means=False)\n",
    "            row_data = {'Variable': \"  White vs others\", 'Tamsulosin': '', 'Finasteride': '', 'Std Difference': f\"{std_diff:.2f}\"}\n",
    "            summary_rows.append(row_data)\n",
    "            # standardize difference is independent of sample size. \n",
    "            # preference: https://support.sas.com/resources/papers/proceedings12/335-2012.pdf\n",
    "            # Drop the temporary dominant ethnicity column\n",
    "            df.drop(columns='dominant_ethnicity', inplace=True)\n",
    "            \n",
    "        for variable in var_list:\n",
    "            if variable in variables:\n",
    "                row_data = {'Variable': f\"    {variable}\"}\n",
    "                for treatment, treatment_name in [(1, 'Tamsulosin'), (0, 'Finasteride')]:\n",
    "                    group = df[df['Treatment'] == treatment]\n",
    "                    if variable in ['start_age', 'duration_year', 'diabetes_duration', 'cci_score']:\n",
    "                        weighted_mean = np.average(group[variable], weights=group[weights_variable])\n",
    "                        weighted_std = np.sqrt(np.average((group[variable]-weighted_mean)**2, weights=group[weights_variable]))\n",
    "                        value = f\"{weighted_mean:.2f} ({weighted_std:.2f})\"\n",
    "                    else:\n",
    "                        weighted_count = group.loc[group[variable] == 1, weights_variable].sum()\n",
    "                        weighted_percentage = (weighted_count / group[weights_variable].sum()) * 100\n",
    "                        value = f\"{weighted_count:.0f} ({weighted_percentage:.2f}%)\"\n",
    "                    \n",
    "                    row_data[treatment_name] = value\n",
    "                \n",
    "                # calculate standardized difference for continuous variables\n",
    "                if category != 'Ethnicity':\n",
    "                    if variable in ['start_age', 'duration_year', 'diabetes_duration', 'cci_score']:\n",
    "                        std_diff = calculate_weighted_standardized_diff(df, variable,weights_variable, for_means=True)\n",
    "                    else: #for catgeorical variables\n",
    "                        std_diff = calculate_weighted_standardized_diff(df, variable,weights_variable, for_means=False)\n",
    "                        \n",
    "                    row_data['Std Difference'] = f\"{std_diff:.2f}\"\n",
    "                \n",
    "                summary_rows.append(row_data)\n",
    "            \n",
    "    summary_table = pd.DataFrame(summary_rows)\n",
    "    return summary_table\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out number of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "#Produce summary table for incidence ratio\n",
    "def incidence_ratio_table(df1, df2, df1_name, df2_name, interval):\n",
    "    # Instantiate the KaplanMeierFitter\n",
    "    kmf_df1 = KaplanMeierFitter()\n",
    "    kmf_df2 = KaplanMeierFitter()\n",
    "\n",
    "    # Fit the data into the model\n",
    "    kmf_df1.fit(df1[\"duration_year\"], df1[\"insulin_status\"])\n",
    "    kmf_df2.fit(df2[\"duration_year\"], df2[\"insulin_status\"])\n",
    "\n",
    "    # Maximum duration_year value\n",
    "    max_duration = max(df1['duration_year'].max(), df2['duration_year'].max())\n",
    "\n",
    "    # Generate time_points list\n",
    "    time_points = [round(i*interval, 2) for i in range(int(max_duration/interval)+1)]\n",
    "\n",
    "    # Calculate cumulative incidence at specific time points\n",
    "    cum_inc_df1 = 1 - kmf_df1.predict(time_points)\n",
    "    cum_inc_df2 = 1 - kmf_df2.predict(time_points)\n",
    "\n",
    "    # Calculate number at risk\n",
    "    num_at_risk_df1 = (len(df1) - (cum_inc_df1 * len(df1))).astype(int)\n",
    "    num_at_risk_df2 = (len(df2) - (cum_inc_df2 * len(df2))).astype(int)\n",
    "\n",
    "    # Create number at risk table\n",
    "    at_risk_table = pd.DataFrame({\n",
    "        'Year': time_points,\n",
    "        f'{df1_name} Number at risk': num_at_risk_df1.values,\n",
    "        f'{df2_name} Number at risk': num_at_risk_df2.values\n",
    "    })\n",
    "\n",
    "    # Create cumulative incidence table\n",
    "    ci_table = pd.DataFrame({\n",
    "        'Year': time_points,\n",
    "        f'{df1_name} Cumulative Incidence': cum_inc_df1.values,\n",
    "        f'{df2_name} Cumulative Incidence': cum_inc_df2.values\n",
    "    })\n",
    "    #print number at risk table\n",
    "    print(f'\\n')\n",
    "    print(at_risk_table.to_string(index = False))\n",
    "\n",
    "    print(f\"\\n Cummulative incidence per year\")\n",
    "    print(ci_table.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaplan-Meier curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Kaplan Meier curve and cummlative incidence\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "def compute_incidence_rate(df, event_column, time_column):\n",
    "    # Calculate the total number of events\n",
    "    total_events = df[event_column].sum()\n",
    "\n",
    "    # Calculate the total person-time at risk\n",
    "    total_person_years = df[time_column].sum()\n",
    "\n",
    "    # Calculate the incidence rate\n",
    "    incidence_rate = round(((total_events / total_person_years)* 10000), 2) #per 10000 person-years\n",
    "\n",
    "    # Calculate the 95% confidence interval\n",
    "    sqrt_events = np.sqrt(total_events)\n",
    "    ci_lower = round(((total_events - 1.96 * sqrt_events) / total_person_years) *10000, 2)\n",
    "    ci_upper = round(((total_events + 1.96 * sqrt_events) / total_person_years)* 10000, 2)\n",
    "\n",
    "    return incidence_rate, ci_lower, ci_upper\n",
    "\n",
    "def cumulative_incidence_and_km_plot(df1, df2, df1_name, df2_name, table_name):\n",
    "    # fit Kaplan-Meier curves and calculate log-rank p-value\n",
    "    kmf_fin = KaplanMeierFitter()\n",
    "    kmf_tam = KaplanMeierFitter()\n",
    "\n",
    "    # fit dataframes curves\n",
    "    kmf_fin.fit(df1['duration_year'], event_observed=df1['insulin_status'], label=df1_name)\n",
    "    kmf_tam.fit(df2['duration_year'], event_observed=df2['insulin_status'], label=df2_name)\n",
    "\n",
    "    # plot Cumulative Incidence curves\n",
    "    # fig, ax2 = plt.subplots(figsize=(12, 6), dpi=300)  # set dpi when creating the figure\n",
    "    ax2 = (1 - kmf_fin.survival_function_).plot(label=f'{df1_name} (Cumulative Incidence)', color='blue', linestyle='-')\n",
    "    (1 - kmf_tam.survival_function_).plot(ax=ax2, label=f'{df2_name} (Cumulative Incidence)', color='red', linestyle='-')\n",
    "    # Set the figure size\n",
    "    ax2.figure.set_size_inches(12, 6)\n",
    "    #ax2.set_title('Cumulative Incidence Over Time')\n",
    "    ax2.set_xlabel('Duration of following-up (years)')\n",
    "    ax2.set_ylabel('Cumulative Incidence of insulin prescriptions')\n",
    "    ax2.legend()\n",
    "\n",
    "\n",
    "    # calculate and print log-rank p-value\n",
    "    results = logrank_test(df1['duration_year'], df2['duration_year'], df1['insulin_status'], df2['insulin_status'], alpha=.99)\n",
    "    print('Log-Rank Test p-value:', results.p_value)\n",
    "\n",
    "    # create a summary table\n",
    "    summary_table = pd.DataFrame({'Treatment Group': [df1_name, df2_name],\n",
    "                                  'Insulin Status 0': [df1['insulin_status'].value_counts()[0], df2['insulin_status'].value_counts()[0]],\n",
    "                                  'Insulin Status 1': [df1['insulin_status'].value_counts()[1], df2['insulin_status'].value_counts()[1]],\n",
    "                                  'p-value': [results.p_value, '']})\n",
    "    print(\"\\nSummary Table:\")\n",
    "    print(summary_table)\n",
    "\n",
    "    # # print number at risk\n",
    "    # print(\"\\nNumber at risk at each time point (years):\")\n",
    "    time_points = [1, 2, 3, 4, 5, 6, 7, 8, 9]  # You can change these time points to your desired values\n",
    "\n",
    "    # calculate cumulative incidence at specific time points (in years)\n",
    "    cum_inc_fin = 1 - kmf_fin.predict(time_points)\n",
    "    cum_inc_tam = 1 - kmf_tam.predict(time_points)\n",
    "    # calculate number at risk\n",
    "    num_at_risk_fin = (len(df1) - (cum_inc_fin * len(df1))).astype(int).rename(f\"{df1_name} at risk\")\n",
    "    num_at_risk_tam = (len(df2) - (cum_inc_tam * len(df2))).astype(int).rename(f\"{df2_name} at risk\")\n",
    "    at_risk_table = pd.DataFrame({'Year': time_points,\n",
    "                                f'{df1_name} Number at risk': num_at_risk_fin,\n",
    "                                f'{df2_name} Number at risk': num_at_risk_tam})\n",
    "    #print number at risk table\n",
    "    print(f'\\n')\n",
    "    print(at_risk_table.to_string(index = False))\n",
    "    #print cummulative incidence table\n",
    "    ci_table = pd.DataFrame({'Year': time_points,\n",
    "                             f'{df1_name} Cumulative Incidence': cum_inc_fin,\n",
    "                             f'{df2_name} Cumulative Incidence': cum_inc_tam})\n",
    "    print(f\"\\n{table_name}:\")\n",
    "    print(ci_table.to_string(index=False))\n",
    "\n",
    "    # Compute the incidence rate and confidence interval for df1 and df2\n",
    "    incidence_rate_df1, ci_lower_df1, ci_upper_df1 = compute_incidence_rate(df1, 'insulin_status', 'duration_year')\n",
    "    incidence_rate_df2, ci_lower_df2, ci_upper_df2 = compute_incidence_rate(df2, 'insulin_status', 'duration_year')\n",
    "\n",
    "    print(f\"Incidence rate for {df1_name}: {incidence_rate_df1} events per 10000 person-year (95% CI: {ci_lower_df1} to {ci_upper_df1})\")\n",
    "    print(f\"Incidence rate for {df2_name}: {incidence_rate_df2} events per 10000 person-year (95% CI: {ci_lower_df2} to {ci_upper_df2})\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Kernel plot for visualisation\n",
    "def plot_kde(df1, df2, column):\n",
    "    df = pd.concat([df1, df2], axis = 0 )\n",
    "    tamsulosin = df[df['Treatment'] == 1][f'{column}']\n",
    "    finasteride = df[df['Treatment'] == 0][f'{column}']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(tamsulosin, shade=True, color='blue', label='Tamsulosin')\n",
    "    sns.kdeplot(finasteride, shade=True, color='red', label='Finasteride')\n",
    "\n",
    "    plt.title(f'{column} Density Plots for Tamsulosin and Finasteride')\n",
    "    plt.xlabel(f'{column}')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box plot\n",
    "def plot_box(df1, df2, column):\n",
    "    tamsulosin = df1[df1['Treatment'] == 1][f'{column}']\n",
    "    finasteride = df2[df2['Treatment'] == 0][f'{column}']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Customize font size and font family\n",
    "    font = {'family': 'Times New Roman', 'size': 16}\n",
    "    plt.rc('font', **font)\n",
    "\n",
    "    # Create a boxplot for each group\n",
    "    plt.boxplot([tamsulosin, finasteride], labels=['Tamsulosin', 'Finasteride'])\n",
    "\n",
    "    plt.title(f'{column} Box Plots for Tamsulosin and Finasteride')\n",
    "    plt.xlabel('Group')\n",
    "    plt.ylabel(f'{column}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "#weighted box_plot\n",
    "def plot_box_weighted(df1, df2, column, weights):\n",
    "    tamsulosin = df1[df1['Treatment'] == 1][[column, weights]]\n",
    "    finasteride = df2[df2['Treatment'] == 0][[column, weights]]\n",
    "\n",
    "    # Resample data according to weights\n",
    "    tamsulosin_resampled = np.repeat(tamsulosin[column], tamsulosin[weights].astype(int))\n",
    "    finasteride_resampled = np.repeat(finasteride[column], finasteride[weights].astype(int))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Create a boxplot for each group\n",
    "    plt.boxplot([tamsulosin_resampled, finasteride_resampled], labels=['Tamsulosin', 'Finasteride'])\n",
    "\n",
    "    plt.title(f'{column} Box Plots for Tamsulosin and Finasteride after weighted')\n",
    "    plt.xlabel('Group')\n",
    "    plt.ylabel(f'{column}')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box_and_weighted_box(df1, df2, column, weights, column_name):\n",
    "    # Create two subplots: one for unweighted data and one for weighted data\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 6), dpi=300)\n",
    "    \n",
    "    # Unweighted box plot\n",
    "    tamsulosin = df1[df1['Treatment'] == 1][column]\n",
    "    finasteride = df2[df2['Treatment'] == 0][column]\n",
    "    axs[0].boxplot([tamsulosin, finasteride], labels=['Tamsulosin', 'Finasteride'])\n",
    "    axs[0].set_title('Box plot in unweighted sample')\n",
    "    # axs[0].set_xlabel('Group')\n",
    "    axs[0].set_ylabel(f'{column_name}')\n",
    "    axs[0].grid(True)  # Add grid-lines\n",
    "\n",
    "    # Weighted box plot\n",
    "    tamsulosin_weighted = df1[df1['Treatment'] == 1][[column, weights]]\n",
    "    finasteride_weighted = df2[df2['Treatment'] == 0][[column, weights]]\n",
    "    tamsulosin_resampled = np.repeat(tamsulosin_weighted[column], tamsulosin_weighted[weights].astype(int))\n",
    "    finasteride_resampled = np.repeat(finasteride_weighted[column], finasteride_weighted[weights].astype(int))\n",
    "    axs[1].boxplot([tamsulosin_resampled, finasteride_resampled], labels=['Tamsulosin', 'Finasteride'])\n",
    "    axs[1].set_title('Box plot in weighted sample')\n",
    "    # axs[1].set_xlabel('Group')\n",
    "    axs[1].set_ylabel(f'{column_name}')\n",
    "    axs[1].grid(True)  # Add grid-lines\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cummulative distribution function plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ecdf(df1, df2, column):\n",
    "    \"\"\"\n",
    "    Compute and plot ECDFs for two unweighted datasets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df1, df2: DataFrame\n",
    "        DataFrames containing the data.\n",
    "    column: str\n",
    "        The column name of the data points for which the ECDF will be computed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of data points\n",
    "    n1 = len(df1[column])\n",
    "    n2 = len(df2[column])\n",
    "\n",
    "    # x-data for the ECDF: sorted data\n",
    "    x1 = np.sort(df1[column])\n",
    "    x2 = np.sort(df2[column])\n",
    "\n",
    "    # y-data for the ECDF: evenly spaced sequence from 1/n to 1\n",
    "    y1 = np.arange(1, n1+1) / n1\n",
    "    y2 = np.arange(1, n2+1) / n2\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x1, y1, label='dataset_1')\n",
    "    plt.plot(x2, y2, label='dataset_2')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel(f'Cumulative Probability of {column}')\n",
    "    plt.title('Empirical Cumulative Distribution Functions')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weighted_ecdf(df1, df2, column, weights, column_name):\n",
    "    \"\"\"\n",
    "    Compute and plot ECDFs for two weighted datasets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df1, df2: DataFrame\n",
    "        DataFrames containing the data and weights.\n",
    "    column: str\n",
    "        The column name of the data points for which the ECDF will be computed.\n",
    "    weights: str\n",
    "        The column name of the weights.\n",
    "    \"\"\"\n",
    "\n",
    "    # Resample data according to weights\n",
    "    resampled_data1 = np.repeat(df1[column], df1[weights].astype(int))\n",
    "    resampled_data2 = np.repeat(df2[column], df2[weights].astype(int))\n",
    "\n",
    "    # Sort data and compute cumulative probabilities\n",
    "    x1 = np.sort(resampled_data1)\n",
    "    y1 = np.arange(1, len(x1)+1) / len(x1)\n",
    "\n",
    "    x2 = np.sort(resampled_data2)\n",
    "    y2 = np.arange(1, len(x2)+1) / len(x2)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x1, y1, label='Dataset 1')\n",
    "    plt.plot(x2, y2, label='Dataset 2')\n",
    "    plt.xlabel(column_name)\n",
    "    plt.ylabel(f'Cumulative Probability of {column_name}')\n",
    "    plt.title('Cumulative Distribution in weighted poplation')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cummulative distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ecdf_and_weighted_ecdf(df1, df2, column, weights, column_name):\n",
    "    \"\"\"\n",
    "    Compute and plot ECDFs for unweighted and weighted datasets in two subplots.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df1, df2: DataFrame\n",
    "        DataFrames containing the data and weights.\n",
    "    column: str\n",
    "        The column name of the data points for which the ECDFs will be computed.\n",
    "    weights: str\n",
    "        The column name of the weights.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of data points\n",
    "    n1 = len(df1[column])\n",
    "    n2 = len(df2[column])\n",
    "\n",
    "    # x-data for the ECDF: sorted data\n",
    "    x1 = np.sort(df1[column])\n",
    "    x2 = np.sort(df2[column])\n",
    "\n",
    "    # y-data for the ECDF: evenly spaced sequence from 1/n to 1\n",
    "    y1 = np.arange(1, n1+1) / n1\n",
    "    y2 = np.arange(1, n2+1) / n2\n",
    "\n",
    "    # Resample data according to weights\n",
    "    resampled_data1 = np.repeat(df1[column], df1[weights].astype(int))\n",
    "    resampled_data2 = np.repeat(df2[column], df2[weights].astype(int))\n",
    "\n",
    "    # Sort data and compute cumulative probabilities for weighted data\n",
    "    x1_weighted = np.sort(resampled_data1)\n",
    "    y1_weighted = np.arange(1, len(x1_weighted)+1) / len(x1_weighted)\n",
    "\n",
    "    x2_weighted = np.sort(resampled_data2)\n",
    "    y2_weighted = np.arange(1, len(x2_weighted)+1) / len(x2_weighted)\n",
    "\n",
    "    # Create the figure and subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 6), dpi=300)\n",
    "    \n",
    "    # Plot unweighted ECDFs\n",
    "    axs[0].plot(x1, y1, label='Tamsulosin') #where treatment = 1\n",
    "    axs[0].plot(x2, y2, label='Finasteride')  #where treatment = 0\n",
    "    axs[0].set_xlabel(column_name)\n",
    "    axs[0].set_ylabel('Proportion <= x')\n",
    "    axs[0].set_title('Cumulative Distribution in unweighted poplation')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot weighted ECDFs\n",
    "    axs[1].plot(x1_weighted, y1_weighted, label='Tamsulosin')\n",
    "    axs[1].plot(x2_weighted, y2_weighted, label='Finasteride')\n",
    "    axs[1].set_xlabel(column_name)\n",
    "    axs[1].set_ylabel('Proportion <= x')\n",
    "    axs[1].set_title('Cumulative Distribution in weighted poplation')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag-time function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lag_time(df, lag_duration):\n",
    "    # Create a copy of the dataframe to avoid modifying the original one\n",
    "    df_lag = df.copy()\n",
    "\n",
    "    # Identify the rows where the event occurred before the lag time\n",
    "    early_event_mask = df_lag['duration_year'] < lag_duration\n",
    "\n",
    "    # For these rows, set the event status to 0 (non-case)\n",
    "    df_lag.loc[early_event_mask, 'insulin_status'] = 0\n",
    "\n",
    "    # Return the modified dataframe\n",
    "    return df_lag\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test case for lag-time function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def test_apply_lag_time():\n",
    "    # Create a test dataframe\n",
    "    data = {\n",
    "        'insulin_status': [0, 1, 1, 0, 1],\n",
    "        'duration_year': [1, 2, 3, 4, 5]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Apply the lag time\n",
    "    df_lag = apply_lag_time(df, 3)\n",
    "\n",
    "    # Check the output\n",
    "    assert df_lag['insulin_status'].tolist() == [0, 0, 1, 0, 1], \"Test failed!\"\n",
    "    assert df_lag['duration_year'].tolist() == [1, 2, 3, 4, 5], \"Test failed!\"\n",
    "\n",
    "# Run the test\n",
    "test_apply_lag_time()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finasteride_df['duration_year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamsulosin_df['duration_year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(finasteride_df, tamsulosin_df, 'diabetes_duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(tamsulosin_df, finasteride_df, 'duration_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(tamsulosin_df, finasteride_df, 'start_age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(tamsulosin_df.query('insulin_status == 1'), finasteride_df.query('insulin_status == 1'), 'duration_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde(tamsulosin_df, finasteride_df, 'cci_score')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-variable Cox-proportional hazard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unadjusted_variables = ['Treatment', 'insulin_status', 'duration_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['Treatment',\n",
    "       'ACE_inhibitors', 'ARBs' ,'Beta_blocker',   'diuretics', 'statin',\n",
    "       #'corticosteroid', \n",
    "       #'second_hospitalisation', \n",
    "       'insulin_status','duration_year',\n",
    "       'start_age', 'cci_score', 'diabetes_duration',\n",
    "       'metformin', 'sulfonylureas',\n",
    "       'ethnicity_Asian', 'ethnicity_Indigenous', 'ethnicity_Not_Stated/Other/Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "from lifelines.statistics import proportional_hazard_test\n",
    "from scipy.stats import chi2_contingency, f_oneway, kruskal\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "def Cox_proportional_model(df1, df2, df1_name, df2_name, variables):\n",
    "    \n",
    "    # Merge the two data frames\n",
    "    df = pd.concat([df1, df2], axis=0)\n",
    "    # Run the Cox proportional hazard model\n",
    "    np.random.seed(42)\n",
    "\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df[variables],\n",
    "        duration_col='duration_year', event_col='insulin_status')\n",
    "\n",
    "    summary_table = cph.summary\n",
    "    \n",
    "    treatment_labels = [df1_name, df2_name]\n",
    "    for i, label in enumerate(treatment_labels):\n",
    "        mask = (df['Treatment'] == i)\n",
    "        patients = mask.sum()\n",
    "        event_count = df[mask]['insulin_status'].sum()\n",
    "        no_event_count = patients - event_count\n",
    "        print(f'Treatment {i} ({label}): {patients} patients, {event_count} events, {no_event_count} censored')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi = 300)\n",
    "\n",
    "    # Plot Cox-proportional hazard\n",
    "    cph.plot_partial_effects_on_outcome('Treatment', [0, 1], cmap='coolwarm', ax=ax)\n",
    "\n",
    "    # Access the lines and change their colors\n",
    "    ax.get_lines()[0].set_color('blue')\n",
    "    ax.get_lines()[1].set_color('red')\n",
    "\n",
    "    ax.set_xlabel('Duration of following-up (years')\n",
    "    ax.set_ylabel('Probability of receiving insulin prescription')\n",
    "    # ax.set_title(f'Survival curves of {df1_name} versus {df2_name}')\n",
    "    ax.legend(labels=treatment_labels)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return summary_table\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "covariates = ['ACE_inhibitors', 'ARBs' ,'Beta_blocker', 'diuretics', 'statin', #medications\n",
    "             #'corticosteroid',\n",
    "             #'second_hospitalisation', \n",
    "             'metformin', 'sulfonylureas', #T2DMmedications\n",
    "             'start_age',\n",
    "             'cci_score', 'diabetes_duration', \n",
    "             'ethnicity_Asian', 'ethnicity_Indigenous','ethnicity_Not_Stated/Other/Unknown']\n",
    "\n",
    "def estimate_propensity_scores(df1, df2):\n",
    "    # Merge the two dataframes\n",
    "    df = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "    # Define the predictors and the outcome variable\n",
    "    X = df[covariates]\n",
    "    y = df['Treatment']\n",
    "\n",
    "    # Estimate propensity scores using logistic regression\n",
    "    logistic_regression = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    logistic_regression.fit(X, y)\n",
    "    df['propensity_score'] = logistic_regression.predict_proba(X)[:, 1]\n",
    "    # Trimming the weights\n",
    "    lower_bound, upper_bound = df['propensity_score'].quantile([0.01, 0.99])  # Modify this line according to your chosen percentiles\n",
    "    df['propensity_score'] = np.where(df['propensity_score'] < lower_bound, lower_bound,\n",
    "                         np.where(df['propensity_score'] > upper_bound, upper_bound, df['propensity_score']))\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaplan Meier-curve after propensity score weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_incidence_weighted(df, df1_name, df2_name):\n",
    "    # fit Kaplan-Meier curves and calculate log-rank p-value\n",
    "    kmf_tam = KaplanMeierFitter()\n",
    "    kmf_fin = KaplanMeierFitter()\n",
    "\n",
    "    #df_1 is finasteride, df_2 is tamsulosin\n",
    "    df1 = df[df['Treatment'] == 0]\n",
    "    df2 = df[df['Treatment'] == 1]\n",
    "\n",
    "    # fit dataframes curves\n",
    "    kmf_tam.fit(df1['duration_year'], event_observed=df1['insulin_status'], label=df1_name, weights=df1['ipw'])\n",
    "    kmf_fin.fit(df2['duration_year'], event_observed=df2['insulin_status'], label=df2_name, weights=df2['ipw'])\n",
    "\n",
    "    # plot Cumulative Incidence curves\n",
    "    ax2 = (1 - kmf_fin.survival_function_).plot(label=f'{df1_name} (Cumulative Incidence)', color='red', linestyle='--')\n",
    "    (1 - kmf_tam.survival_function_).plot(ax=ax2, label=f'{df2_name} (Cumulative Incidence)', color='blue', linestyle='-')\n",
    "    ax2.set_title('Cumulative Incidence Over Time')\n",
    "    ax2.set_xlabel('Time (years)')\n",
    "    ax2.set_ylabel('Cumulative Incidence')\n",
    "    ax2.legend()\n",
    "\n",
    "    # calculate and print log-rank p-value\n",
    "    results = logrank_test(df1['duration_year'], df2['duration_year'], df1['insulin_status'], df2['insulin_status'], alpha=.99)\n",
    "    print('Log-Rank Test p-value:', results.p_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverese probability weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cox_ipw_and_graphs(df, df1_control_name,df2_treatment_name):\n",
    "\n",
    "   # Calculate inverse probability weights\n",
    "    df['ipw'] = np.where(df['Treatment'] == 1, 1/df['propensity_score'], 1/(1 - df['propensity_score']))\n",
    "\n",
    "    # Weight trimming at 1st and 99th percentile\n",
    "    lower_bound = df['ipw'].quantile(0.01)\n",
    "    upper_bound = df['ipw'].quantile(0.99)\n",
    "    df['ipw'] = df['ipw'].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    #Output summary table\n",
    "    print(summarize_variables_after_weighted(df,variables, grouped_variables, 'ipw'))\n",
    "    \n",
    "    #boxplot for weighted data to check distribution\n",
    "    plot_box_and_weighted_box(df[df['Treatment'] == 1], df[df['Treatment'] == 0], 'cci_score', 'ipw', 'CCI score')\n",
    "    plot_box_and_weighted_box(df[df['Treatment'] == 1], df[df['Treatment'] == 0], 'diabetes_duration', 'ipw', 'Diabetes duration')\n",
    "    plot_box_and_weighted_box(df[df['Treatment'] == 1], df[df['Treatment'] == 0], 'start_age', 'ipw', 'Age')\n",
    "    \n",
    "    #plot ecdf for weighted data\n",
    "    plot_ecdf_and_weighted_ecdf(df[df['Treatment'] == 1], df[df['Treatment'] == 0], 'cci_score', 'ipw', 'CCI score')\n",
    "    plot_ecdf_and_weighted_ecdf(df[df['Treatment'] == 1], df[df['Treatment'] == 0], 'diabetes_duration', 'ipw', 'Diabetes duration')\n",
    "    plot_ecdf_and_weighted_ecdf(df[df['Treatment'] == 1], df[df['Treatment'] == 0], 'start_age', 'ipw', 'Age')\n",
    "    \n",
    "    # Fit the Cox proportional hazard model with IPW\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df[['Treatment', \n",
    "                'duration_year','insulin_status', 'ipw']], \n",
    "            duration_col='duration_year', event_col='insulin_status', weights_col='ipw',\n",
    "            robust = True)\n",
    "    \n",
    "    #Counting patients in each treatment group\n",
    "    treatment_labels = [df1_control_name, df2_treatment_name]\n",
    "    for i, label in enumerate(treatment_labels):\n",
    "        mask = (df['Treatment'] == i)\n",
    "        patients = mask.sum()\n",
    "        event_count = df[mask]['insulin_status'].sum()\n",
    "        no_event_count = patients - event_count\n",
    "\n",
    "        # Calculate the weighted event count\n",
    "        weighted_event_count = (df[mask]['insulin_status'] * df[mask]['ipw']).sum()\n",
    "\n",
    "        # Calculate the total number of patients in the weighted population\n",
    "        weighted_patient_count = df[mask]['ipw'].sum()\n",
    "\n",
    "        print(f'''Treatment {i} ({label}): {patients} patients, {event_count} events, {no_event_count} censored, \n",
    "              {round(weighted_event_count,0)} weighted events, {round(weighted_patient_count,0)} total patients in weighted population''')\n",
    "                    \n",
    "    \n",
    "    # Plot Cox-proportional hazard\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    cph.plot_partial_effects_on_outcome('Treatment', [0, 1], cmap='coolwarm', ax=ax)\n",
    "\n",
    "    ax.set_xlabel('Duration of following-up (years)')\n",
    "    ax.set_ylabel('Probability of receiving insulin prescriptions')\n",
    "    # ax.set_title(f'Survival curves of {df1_control_name} versus {df2_treatment_name}')\n",
    "    ax.legend(labels=[df1_control_name, df2_treatment_name])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return cph.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cox_ipw(df, df1_control_name,df2_treatment_name):\n",
    "\n",
    "   # Calculate inverse probability weights\n",
    "    df['ipw'] = np.where(df['Treatment'] == 1, 1/df['propensity_score'], 1/(1 - df['propensity_score']))\n",
    "\n",
    "    # Weight trimming at 1st and 99th percentile\n",
    "    lower_bound = df['ipw'].quantile(0.01)\n",
    "    upper_bound = df['ipw'].quantile(0.99)\n",
    "    df['ipw'] = df['ipw'].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    #Output summary table\n",
    "    print(summarize_variables_after_weighted(df,variables, grouped_variables, 'ipw'))\n",
    "    \n",
    "     # Fit the Cox proportional hazard model with IPW\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df[['Treatment', \n",
    "                'duration_year','insulin_status', 'ipw']], \n",
    "            duration_col='duration_year', event_col='insulin_status', weights_col='ipw',\n",
    "            robust = True)\n",
    "    \n",
    "    \n",
    "    #Counting patients in each treatment group\n",
    "    treatment_labels = [df1_control_name, df2_treatment_name]\n",
    "    for i, label in enumerate(treatment_labels):\n",
    "        mask = (df['Treatment'] == i)\n",
    "        patients = mask.sum()\n",
    "        event_count = df[mask]['insulin_status'].sum()\n",
    "        no_event_count = patients - event_count\n",
    "\n",
    "        # Calculate the weighted event count\n",
    "        weighted_event_count = (df[mask]['insulin_status'] * df[mask]['ipw']).sum()\n",
    "\n",
    "        # Calculate the total number of patients in the weighted population\n",
    "        weighted_patient_count = df[mask]['ipw'].sum()\n",
    "\n",
    "        print(f'''Treatment {i} ({label}): {patients} patients, {event_count} events, {no_event_count} censored, \n",
    "              {round(weighted_event_count,0)} weighted events, {round(weighted_patient_count,0)} total patients in weighted population''')\n",
    "                \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi = 300)\n",
    "\n",
    "    # Plot Cox-proportional hazard\n",
    "    cph.plot_partial_effects_on_outcome('Treatment', [0, 1], cmap='coolwarm', ax=ax)\n",
    "\n",
    "    # Access the lines and change their colors\n",
    "    ax.get_lines()[0].set_color('blue')\n",
    "    ax.get_lines()[1].set_color('red')\n",
    "\n",
    "    ax.set_xlabel('Duration of following-up (years)')\n",
    "    ax.set_ylabel('Probability of receiving insulin prescriptions')\n",
    "    # ax.set_title(f'Survival curves of {df1_control_name} versus {df2_treatment_name}')\n",
    "    ax.legend(labels=[df1_control_name, df2_treatment_name])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return cph.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cox_ipw_strata(df, df1_control_name,df2_treatment_name):\n",
    "\n",
    "   # Calculate inverse probability weights\n",
    "    df['ipw'] = np.where(df['Treatment'] == 1, 1/df['propensity_score'], 1/(1 - df['propensity_score']))\n",
    "\n",
    "    # Weight trimming at 1st and 99th percentile\n",
    "    lower_bound = df['ipw'].quantile(0.01)\n",
    "    upper_bound = df['ipw'].quantile(0.99)\n",
    "    df['ipw'] = df['ipw'].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    #Output summary table\n",
    "    print(summarize_variables_after_weighted(df,variables, grouped_variables, 'ipw'))\n",
    "    \n",
    "    # Fit the Cox proportional hazard model with IPW\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df[['Treatment', \n",
    "                'duration_year','insulin_status', 'ipw']], \n",
    "            duration_col='duration_year', event_col='insulin_status', weights_col='ipw',\n",
    "            robust = True)\n",
    "    \n",
    "    \n",
    "    #Counting patients in each treatment group\n",
    "    treatment_labels = [df1_control_name, df2_treatment_name]\n",
    "    for i, label in enumerate(treatment_labels):\n",
    "        mask = (df['Treatment'] == i)\n",
    "        patients = mask.sum()\n",
    "        event_count = df[mask]['insulin_status'].sum()\n",
    "        no_event_count = patients - event_count\n",
    "\n",
    "        # Calculate the weighted event count\n",
    "        weighted_event_count = (df[mask]['insulin_status'] * df[mask]['ipw']).sum()\n",
    "\n",
    "        # Calculate the total number of patients in the weighted population\n",
    "        weighted_patient_count = df[mask]['ipw'].sum()\n",
    "\n",
    "        print(f'''Treatment {i} ({label}): {patients} patients, {event_count} events, {no_event_count} censored, \n",
    "              {round(weighted_event_count,0)} weighted events, {round(weighted_patient_count,0)} total patients in weighted population''')\n",
    "                \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi = 300)\n",
    "\n",
    "    # Plot Cox-proportional hazard\n",
    "    cph.plot_partial_effects_on_outcome('Treatment', [0, 1], cmap='coolwarm', ax=ax)\n",
    "\n",
    "    # Access the lines and change their colors\n",
    "    ax.get_lines()[0].set_color('blue')\n",
    "    ax.get_lines()[1].set_color('red')\n",
    "\n",
    "    ax.set_xlabel('Duration of following-up (years)')\n",
    "    ax.set_ylabel('Probability of receiving insulin prescriptions')\n",
    "    # ax.set_title(f'Survival curves of {df1_control_name} versus {df2_treatment_name}')\n",
    "    ax.legend(labels=[df1_control_name, df2_treatment_name])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return cph.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_assumption_cox(df1, df2, df1_name, df2_name, variables):\n",
    "    \n",
    "    # Merge the two data frames\n",
    "    df = pd.concat([df1, df2], axis=0)\n",
    "    # Run the Cox proportional hazard model\n",
    "    np.random.seed(42)\n",
    "\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df[variables],\n",
    "        duration_col='duration_year', event_col='insulin_status')\n",
    "\n",
    "    summary_table = cph.summary\n",
    "\n",
    "    # Check the proportional hazard assumption\n",
    "    df_check_assumption = df.drop('new_enc_nhi', axis=1)\n",
    "    df_check_assumption= df_check_assumption.reset_index(drop=True)\n",
    "    # Check the proportional hazards assumption\n",
    "    # Select only the columns you're interested in\n",
    "    columns_of_interest = variables\n",
    "    df_subset = df_check_assumption[columns_of_interest].copy()\n",
    "    cph.check_assumptions(df_subset, p_value_threshold=0.05, show_plots=True, \n",
    "                       )\n",
    "        # Print the summary table\n",
    "    treatment_labels = [df1_name, df2_name]\n",
    "    for i, label in enumerate(treatment_labels):\n",
    "        mask = (df['Treatment'] == i)\n",
    "        patients = mask.sum()\n",
    "        event_count = df[mask]['insulin_status'].sum()\n",
    "        no_event_count = patients - event_count\n",
    "        print(f'Treatment {i} ({label}): {patients} patients, {event_count} events, {no_event_count} censored')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    cph.plot_partial_effects_on_outcome('Treatment', [0, 1], cmap='coolwarm', ax=ax)\n",
    "\n",
    "    ax.set_xlabel('Duration (years)')\n",
    "    ax.set_ylabel('Survival probability')\n",
    "    ax.set_title(f'Survival curves of {df1_name} versus {df2_name}')\n",
    "    ax.legend(labels=treatment_labels)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratification by cci score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_strata_cci = ['Treatment',\n",
    "       'ACE_inhibitors', 'ARBs' ,'Beta_blocker',   'diuretics', 'statin',\n",
    "       #'corticosteroid', \n",
    "       #'second_hospitalisation', \n",
    "       'metformin', 'sulfonylureas',\n",
    "       'insulin_status','duration_year',\n",
    "       'start_age', #'cci_score', \n",
    "       'diabetes_duration',\n",
    "       'ethnicity_Asian', 'ethnicity_Indigenous', 'ethnicity_Not_Stated/Other/Unknown']\n",
    "#percentile strata\n",
    "def run_cox_models_percentile_strata(df1, df2, df1_name, df2_name):\n",
    "    # Merge the two dataframes\n",
    "    aggregate_df = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "    # Calculate the percentile values for cci_score\n",
    "    median_cci = aggregate_df['cci_score'].quantile(0.5)\n",
    "    tertile_1_cci = aggregate_df['cci_score'].quantile(1/3)\n",
    "    tertile_2_cci = aggregate_df['cci_score'].quantile(2/3)\n",
    "\n",
    "    print(f\"Median CCI score: {median_cci:.2f}\")\n",
    "\n",
    "    # Define the strata based on cci_score percentiles\n",
    "    strata = {\n",
    "        'scenario_1': {\n",
    "            'lower': (0, median_cci),\n",
    "            'higher': (median_cci, np.inf)\n",
    "        },\n",
    "        # 'scenario_2': {\n",
    "        #     'tertile_1': (0, tertile_1_cci),\n",
    "        #     'tertile_2': (tertile_1_cci, tertile_2_cci),\n",
    "        #     'tertile_3': (tertile_2_cci, np.inf)\n",
    "        # }\n",
    "    }\n",
    "\n",
    "    # Loop through the scenarios and strata and run the Cox proportional hazard model for each stratum\n",
    "    for scenario, strata_ranges in strata.items():\n",
    "        print(f\"{scenario.capitalize()}:\")\n",
    "            # add this before your loop\n",
    "        all_summary_tables = []\n",
    "        for stratum_name, cci_range in strata_ranges.items():\n",
    "            print(f\"{stratum_name.capitalize()} stratum:\")\n",
    "\n",
    "            # Filter the DataFrames based on the cci_score range for the current stratum\n",
    "            filtered_df1 = df1.loc[(df1['cci_score'] > cci_range[0]) & (df1['cci_score'] <= cci_range[1])]\n",
    "            filtered_df2 = df2.loc[(df2['cci_score'] > cci_range[0]) & (df2['cci_score'] <= cci_range[1])]\n",
    "\n",
    "            #calculate propensity score for each stratum\n",
    "            total_filtered_df_propensity_score = estimate_propensity_scores(filtered_df1, filtered_df2)\n",
    "\n",
    "            # Run the Cox proportional hazard model for the filtered DataFrames\n",
    "            test_table_name = f\"{stratum_name.capitalize()} Stratum ({scenario}) - {df1_name} vs {df2_name}\"\n",
    "            summary_table = cox_ipw_strata(total_filtered_df_propensity_score, df1_name, df2_name)\n",
    "            \n",
    "            all_summary_tables.append(summary_table)\n",
    "            \n",
    "    # add this at the end of your function\n",
    "    return all_summary_tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaplan Meier\n",
    "cumulative_incidence_and_km_plot(finasteride_df,tamsulosin_df, 'Finasteride','Tamsulosin','Cumulative Incidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_assumption_cox(finasteride_df, tamsulosin_df, 'Finasteride', 'Tamsulosin', variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diabetes duration visualisation\n",
    "finasteride_df['diabetes_duration'].hist(bins=20, alpha=0.5, label='Finasteride')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamsulosin['diabetes_duration'].hist(bins=20, alpha=0.5, label='Tamsulosin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unadjusted Cox model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cox_proportional_model(tamsulosin_df, finasteride_df, 'Finasteride_unadjusted', 'Tamsulosin_unadjusted', unadjusted_variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusted Hazard ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cox_proportional_model(tamsulosin_df, finasteride_df, 'Finasteride', 'Tamsulosin', variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPTW of primary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_variables_before_weighted(fin_tam_df, variables, grouped_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the median of tamsulosin and finasteride duration_year variable\n",
    "print(f\"Median of duration of finasteride is {finasteride_df['duration_year'].median()}\")\n",
    "print(f\"Median of duration of tamsulosin is {tamsulosin['duration_year'].median()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#propensity score for primary analysis\n",
    "propensity_score_primary_df = estimate_propensity_scores(tamsulosin_df, finasteride_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propensity_score_primary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check assumption IPTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_assumption_IPTW(df, df1_name, df2_name, variables):\n",
    "    # Calculate inverse probability weights\n",
    "    df['ipw'] = np.where(df['Treatment'] == 1, 1/df['propensity_score'], 1/(1 - df['propensity_score']))\n",
    "\n",
    "    # Weight trimming at 1st and 99th percentile\n",
    "    lower_bound = df['ipw'].quantile(0.01)\n",
    "    upper_bound = df['ipw'].quantile(0.99)\n",
    "    df['ipw'] = df['ipw'].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df[variables],\n",
    "        duration_col='duration_year', event_col='insulin_status', weights_col='ipw')\n",
    "\n",
    "    summary_table = cph.summary\n",
    "\n",
    "    # Check the proportional hazard assumption\n",
    "    df_check_assumption = df.drop('new_enc_nhi', axis=1)\n",
    "    df_check_assumption= df_check_assumption.reset_index(drop=True)\n",
    "    # Check the proportional hazards assumption\n",
    "    # Select only the columns you're interested in\n",
    "    columns_of_interest = variables\n",
    "    df_subset = df_check_assumption[columns_of_interest].copy()\n",
    "    cph.check_assumptions(df_subset, p_value_threshold=0.05, show_plots=True, \n",
    "                       )\n",
    "\n",
    "    return summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_assumption_IPTW(propensity_score_primary_df, 'Finasteride', 'Tamsulosin', variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cox_ipw_and_graphs(propensity_score_primary_df, 'Finasteride', 'Tamsulosin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_incidence_weighted(propensity_score_primary_df, 'Finasteride', 'Tamsulosin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-month lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check lifelines version\n",
    "import lifelines\n",
    "lifelines.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamsulosin_df['duration_year'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 months lag\n",
    "# finasteride data set\n",
    "finasteride_3_months_lag = apply_lag_time(finasteride_df, 0.25)\n",
    "\n",
    "# tamsulosin data set\n",
    "tamsulosin_3_months_lag = apply_lag_time(tamsulosin_df, 0.25)\n",
    "\n",
    "print(f'Total finasteride patients after 3 months lag: {len(finasteride_3_months_lag)}')\n",
    "print(f'Total tamsulosin patients after 3 months lag: {len(tamsulosin_3_months_lag)}')\n",
    "\n",
    "#merge data sets\n",
    "combined_3_month_lag_df = pd.concat([tamsulosin_3_months_lag, finasteride_3_months_lag], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_variables_before_weighted(combined_3_month_lag_df, variables, grouped_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_incidence_and_km_plot(finasteride_3_months_lag, tamsulosin_3_months_lag, 'Finasteride', 'Tamsulosin', 'Cumulative Incidence for 3-month lag')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cox-model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unadjusted variables\n",
    "Cox_proportional_model(tamsulosin_3_months_lag, finasteride_3_months_lag, 'Finasteride', 'Tamsulosin', unadjusted_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusted\n",
    "Cox_proportional_model(tamsulosin_3_months_lag, finasteride_3_months_lag, 'finasteride','tamsulosin', variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#propensity score for 3 months lag\n",
    "propensity_score_df_3_month_lag= estimate_propensity_scores(finasteride_3_months_lag, tamsulosin_3_months_lag)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_variables_before_weighted(combined_3_month_lag_df,summary_variables,grouped_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipw 3 monhts lag\n",
    "cox_ipw(propensity_score_df_3_month_lag, 'Finasteride', 'Tamsulosin', )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-month lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 months lag\n",
    "# finasteride data set\n",
    "finasteride_6_months_lag = apply_lag_time(finasteride_df, 0.5)\n",
    "\n",
    "# tamsulosin data set\n",
    "tamsulosin_6_months_lag = apply_lag_time(tamsulosin_df, 0.5)\n",
    "\n",
    "print(f'Total finasteride patients after 6 months lag: {len(finasteride_6_months_lag)}')\n",
    "print(f'Total tamsulosin patients after 6 months lag: {len(tamsulosin_6_months_lag)}')\n",
    "\n",
    "#merge data sets\n",
    "combined_3_month_lag_df = pd.concat([tamsulosin_6_months_lag, finasteride_6_months_lag], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaplan-Meier for 6 months lag\n",
    "cumulative_incidence_and_km_plot(finasteride_6_months_lag, tamsulosin_6_months_lag, 'Finasteride', 'Tamsulosin', 'Cumulative Incidence for 6-month lag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 6 months lag\n",
    "# # finasteride data set\n",
    "# finasteride_6_months_lag = apply_lag_time(finasteride_df, 0.5)\n",
    "\n",
    "# # tamsulosin data set\n",
    "# tamsulosin_6_months_lag = apply_lag_time(tamsulosin_df, 0.5)\n",
    "\n",
    "print(f'Total finasteride patients after 6 months lag: {len(finasteride_6_months_lag)}')\n",
    "print(f'Total tamsulosin patients after 6 months lag: {len(tamsulosin_6_months_lag)}')\n",
    "\n",
    "#merge data sets\n",
    "combined_6_month_lag_df = pd.concat([tamsulosin_6_months_lag, finasteride_6_months_lag], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unadjusted\n",
    "Cox_proportional_model(tamsulosin_6_months_lag, finasteride_6_months_lag, 'Finasteride', 'Tamsulosin', unadjusted_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusted\n",
    "Cox_proportional_model(tamsulosin_6_months_lag, finasteride_6_months_lag, 'tamsulosin', 'finasteride', variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#propensity score calculation\n",
    "propensity_score_df_6_month_lag= estimate_propensity_scores(finasteride_6_months_lag, tamsulosin_6_months_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPTW for 6 months lag\n",
    "cox_ipw(propensity_score_df_6_month_lag, 'Finasteride', 'Tamsulosin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9-month lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the data sets for 9-month lag\n",
    "# finasteride data set\n",
    "finasteride_9_months_lag = apply_lag_time(finasteride_df, 0.75)\n",
    "#tamsulosin data set\n",
    "tamsulosin_9_months_lag = apply_lag_time(tamsulosin_df, 0.75)\n",
    "print(f'There are {len(finasteride_9_months_lag)} patients in the finasteride data set after 9 months lag')\n",
    "print(f'There are {len(tamsulosin_9_months_lag)} patients in the tamsulosin data set after 9 months lag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted incidence curve\n",
    "cumulative_incidence_and_km_plot(finasteride_9_months_lag, tamsulosin_9_months_lag, 'Finasteride', 'Tamsulosin', 'Cumulative Incidence for 9-month lag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Un-adjusted\n",
    "Cox_proportional_model(tamsulosin_9_months_lag,finasteride_9_months_lag, 'Finasteride', 'Tamsulosin', unadjusted_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPTW for 9-month lag\n",
    "propensity_score_df_9_month_lag= estimate_propensity_scores(finasteride_9_months_lag, tamsulosin_9_months_lag)\n",
    "cox_ipw(propensity_score_df_9_month_lag, 'Finasteride', 'Tamsulosin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-year lag analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 months lag\n",
    "# finasteride data set\n",
    "finasteride_12_months_lag = apply_lag_time(finasteride_df, 1)\n",
    "\n",
    "# tamsulosin data set\n",
    "tamsulosin_12_months_lag = apply_lag_time(tamsulosin_df, 1)\n",
    "\n",
    "#combined df for 12 months lag\n",
    "combined_12_month_lag_df = pd.concat([finasteride_12_months_lag, tamsulosin_12_months_lag], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cummulative incidence\n",
    "cumulative_incidence_and_km_plot(finasteride_12_months_lag, tamsulosin_12_months_lag, 'Finasteride', 'Tamsulosin', 'Cumulative Incidence for 12-month lag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crude HR for 1 year lag\n",
    "Cox_proportional_model(tamsulosin_12_months_lag, finasteride_12_months_lag, 'tamsulosin', 'finasteride', unadjusted_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate propensity score for 12 months lag\n",
    "propensity_score_df_12_months_lag = estimate_propensity_scores(tamsulosin_12_months_lag, finasteride_12_months_lag)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IPTW for 12-month lag  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary variables\n",
    "summarize_variables_before_weighted(combined_12_month_lag_df, summary_variables, grouped_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPTW for 12-month lag\n",
    "cox_ipw(propensity_score_df_12_months_lag, 'Finasteride', 'Tamsulosin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strata for primary analysis\n",
    "run_cox_models_percentile_strata(finasteride_df, tamsulosin_df, 'Finasteride', 'Tamsulosin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Study data\n",
    "studies = ['Main analysis','3-month lag', '6-month lag', '9-month lag', '1-year lag', 'Lower stratum', 'Higher stratum']\n",
    "mean = [1.27, 1.24, 1.26, 1.23, 1.15, 1.34, 1.20 ]\n",
    "ci_lower = [0.95, 0.90, 0.90, 0.86, 0.77, 0.84, 0.82 ]\n",
    "ci_upper = [1.72, 1.71, 1.76, 1.77, 1.72, 2.14, 1.76 ]\n",
    "\n",
    "# Create a new figure and a subplot\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi = 300)\n",
    "\n",
    "# Plot the mean values with larger markers\n",
    "ax.scatter(mean, list(range(len(studies))), marker='s', color='red', s=100)\n",
    "\n",
    "# Plot the confidence intervals\n",
    "for i, study in enumerate(studies):\n",
    "    ax.plot([ci_lower[i], ci_upper[i]], [i, i], color='black')\n",
    "\n",
    "# Set the x-axis limits to be centered around 1\n",
    "ax.set_xlim(0.5, 2)\n",
    "\n",
    "# Remove the borders of the plot and y axis\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "# Add a vertical line at x=1.0\n",
    "ax.axvline(x=1.0, color='black', linestyle='--')\n",
    "\n",
    "# Set the x-axis ticks\n",
    "ax.set_xticks([0.5, 1.0, 2.0, 3.0])\n",
    "\n",
    "# Remove labels and title\n",
    "ax.set_xlabel('')\n",
    "ax.set_title('')\n",
    "\n",
    "# Invert the y-axis\n",
    "\n",
    "ax.invert_yaxis()# Annotate the names of the studies at each point\n",
    "for i, study in enumerate(studies):\n",
    "    ax.text(0.4, i, study, ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
